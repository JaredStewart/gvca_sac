{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659ac7a-01db-443d-95e8-f1ded071c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "import textwrap\n",
    "\n",
    "import config\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c6a5b-3f0f-43e8-a016-9c3ed6288af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d9846-0117-465c-8312-b491a82a0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed/2023.csv')\n",
    "df = df[~df['Empty Response']].replace(\"-\", pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed5217-fefb-4368-ad51-6835183bafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c2c02-0e13-4f0c-880c-3234a073818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_by_parents = False\n",
    "\n",
    "\n",
    "def calculate_question_totals(df_):\n",
    "    results = []\n",
    "    filters = {\n",
    "        \"Year 1 Families\": pd.to_numeric(df_[\"Years at GVCA\"]) == 1,\n",
    "        \"Not Year 1 Families\": pd.to_numeric(df_[\"Years at GVCA\"]) > 1,\n",
    "        \"Year 3 or Less Families\": pd.to_numeric(df_[\"Years at GVCA\"]) <= 3,\n",
    "        \"Year 4 or More Families\": pd.to_numeric(df_[\"Years at GVCA\"]) > 3,\n",
    "        \"Minority\": df_[\"Minority\"] == \"Yes\",\n",
    "        \"Not Minority\": df_[\"Minority\"] != \"Yes\",\n",
    "        \"Support\": df_[\"IEP, 504, ALP, or Read\"] == \"Yes\",\n",
    "        \"Not Support\": df_[\"IEP, 504, ALP, or Read\"] != \"Yes\",\n",
    "    }\n",
    "\n",
    "    for question in config.questions_for_each_school_level:\n",
    "        response_levels = config.question_responses.get(question, [])\n",
    "        \n",
    "        for response in response_levels:\n",
    "            response_data = {\"Question\": question, \"Response\": response}\n",
    "            \n",
    "            schoolwide_counts, schoolwide_total = _calculate_totals(df_, question, response, config.levels, weight_by_parents)\n",
    "            response_data.update(_format_counts_and_percentages(\"total\", schoolwide_counts, schoolwide_total, response))\n",
    "            \n",
    "            for level in config.levels:\n",
    "                level_counts, level_total = _calculate_totals(df_, question, response, [level], weight_by_parents)\n",
    "                response_data.update(_format_counts_and_percentages(level, level_counts, level_total, response))\n",
    "            \n",
    "            for filter_name, filter_condition in filters.items():\n",
    "                filtered_counts, filtered_total = _calculate_totals(df_[filter_condition], question, response, config.levels, weight_by_parents)\n",
    "                response_data.update(_format_counts_and_percentages(filter_name, filtered_counts, filtered_total, response))\n",
    "            \n",
    "            results.append(response_data)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def _calculate_totals(df_, question, response, levels, weight_by_parents):\n",
    "    \"\"\"Helper to calculate counts and totals for given levels.\"\"\"\n",
    "    totals = {}\n",
    "    overall_total = 0\n",
    "\n",
    "    for level in levels:\n",
    "        column_name = f\"({level}) {question}\"\n",
    "        if column_name in df_.columns:\n",
    "            filtered_df = df_[df_[column_name] == response]\n",
    "\n",
    "            if weight_by_parents:\n",
    "                response_sum = filtered_df[\"N Parents Represented\"].astype(float).sum()\n",
    "                level_total = df_[~df_[column_name].isna()][\"N Parents Represented\"].astype(float).sum()\n",
    "            else:\n",
    "                response_sum = len(filtered_df)\n",
    "                level_total = len(df_[column_name].dropna())\n",
    "\n",
    "            totals[response] = totals.get(response, 0) + response_sum\n",
    "            overall_total += level_total\n",
    "\n",
    "    return totals, overall_total\n",
    "\n",
    "def _format_counts_and_percentages(label, counts, total, response):\n",
    "    \"\"\"Helper to format counts and percentages for a given response.\"\"\"\n",
    "    count = counts.get(response, 0)\n",
    "    percentage = (count / total) * 100 if total > 0 else 0\n",
    "    return {f\"N_{label}\": count, f\"%_{label}\": percentage}\n",
    "\n",
    "rolled_up_data = calculate_question_totals(df)\n",
    "rolled_up_data.to_excel(\"2023_rolled_up_data.xlsx\", index=False)\n",
    "rolled_up_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9f88e-88ff-4130-b0d2-b7def2c8bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top_two_from_rollup(rolled_up_data):\n",
    "    results = []\n",
    "\n",
    "    for question in config.questions_for_each_school_level:\n",
    "        top_two_responses = config.question_responses.get(question, [])[:2]  # Get first two satisfaction levels\n",
    "        \n",
    "        # Filter the rolled-up data for relevant responses\n",
    "        filtered_data = rolled_up_data[(rolled_up_data[\"Question\"] == question)]\n",
    "            # ()\n",
    "\n",
    "        if filtered_data.empty:\n",
    "            continue\n",
    "\n",
    "        response_data = {\"Question\": question}\n",
    "\n",
    "        # Aggregate across all relevant columns (e.g., total, school levels, and filters)\n",
    "        for column in rolled_up_data.columns:\n",
    "            if column.startswith(\"N_\"):  # Sum counts for relevant responses\n",
    "                total_count = filtered_data[column].sum()\n",
    "                total_responses = filtered_data[filtered_data[\"Response\"].isin(top_two_responses)][column].sum()\n",
    "\n",
    "                response_data[column] = total_responses\n",
    "                response_data[column.replace(\"N_\", \"%_\")] = (total_responses / total_count) * 100 if total_responses > 0 else 0\n",
    "\n",
    "        results.append(response_data)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "top_two = calculate_top_two_rollup(rolled_up_data)\n",
    "top_two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbee241-771e-4c23-a231-19373513f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacked_bar_chart(\n",
    "    title: str,\n",
    "    x_axis_label: str,\n",
    "    x_data_labels: list,\n",
    "    proportions: dict,\n",
    "    savefig=False,\n",
    "    subfolder=\"artifacts\",\n",
    "    \n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save a stacked bar chart to ./artifacts/\n",
    "    \"\"\"\n",
    "    r1 = [proportions[question][3] for question in config.questions_for_each_school_level if question not in config.has_free_response]\n",
    "    r2 = [proportions[question][2] for question in config.questions_for_each_school_level if question not in config.has_free_response]\n",
    "    r3 = [proportions[question][1] for question in config.questions_for_each_school_level if question not in config.has_free_response]\n",
    "    r4 = [proportions[question][0] for question in config.questions_for_each_school_level if question not in config.has_free_response]\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize = (20, 8))\n",
    "    ax.bar(\n",
    "        x_data_labels,\n",
    "        r4,\n",
    "        label=\"Very\",\n",
    "        color=\"#6caf40\",\n",
    "        bottom=[q1 + q2 + q3 for q1, q2, q3 in zip(r1, r2, r3)],\n",
    "    )\n",
    "    ax.bar(\n",
    "        x_data_labels,\n",
    "        r3,\n",
    "        label=\"Satisfied\",\n",
    "        color=\"#4080af\",\n",
    "        bottom=[q1 + q2 for q1, q2 in zip(r1, r2)],\n",
    "    )\n",
    "    ax.bar(x_data_labels, r2, label=\"Somewhat\", color=\"#f6c100\", bottom=r1)\n",
    "    ax.bar(x_data_labels, r1, label=\"Not\", color=\"#ae3f3f\")\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_axis_label)\n",
    "    ax.set_ylabel(\"Proportion\")\n",
    "\n",
    "    # Shrink current axis by 20%\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    \n",
    "    # Put a legend to the right of the current axis\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if savefig:\n",
    "        if not os.path.exists(subfolder):\n",
    "            os.mkdir(subfolder)\n",
    "        plt.savefig(\n",
    "            f\"{subfolder}/{title}\",\n",
    "            transparent=True,\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "def to_proportions_and_labels(df, col):\n",
    "    print(col)\n",
    "    response_proportions = (\n",
    "        df.groupby([\"Question\", \"Response\"])[col]\n",
    "        .sum()\n",
    "        .unstack(fill_value=0)  # Pivot so that each response is a column\n",
    "    )\n",
    "\n",
    "    # Normalize by row sum to get proportions\n",
    "    response_proportions = response_proportions.div(response_proportions.sum(axis=1), axis=0)\n",
    "\n",
    "    proportions = {}\n",
    "    labels = []\n",
    "    for question in config.questions_for_each_school_level:\n",
    "        score = 0\n",
    "        if question in config.has_free_response:\n",
    "            continue\n",
    "        proportions[question] = []\n",
    "        n_options = len(config.question_responses.get(question, []))\n",
    "        for i, response in enumerate(config.question_responses.get(question, [])):\n",
    "            proportion = response_proportions.loc[question, response]\n",
    "            proportions[question].append(proportion)\n",
    "            score += proportion*(n_options-i)\n",
    "        labels.append(f\"{textwrap.fill(question, 35)}\\n({score:.2f})\")\n",
    "\n",
    "    return proportions, labels\n",
    "\n",
    "def plot_sequence(grouping, df_, savefig=False):\n",
    "    splits = [\n",
    "        (\"All Responses\", \"N_total\"),\n",
    "        (\"Grammar Responses\", \"N_Grammar\"),\n",
    "        (\"Middle Responses\", \"N_Middle\"),\n",
    "        (\"Upper Responses\", \"N_Upper\"),\n",
    "        (\"Minority Responses\", \"N_Minority\"),\n",
    "        (\"Support Responses\", \"N_Support\"),\n",
    "    ]\n",
    "\n",
    "    for split in splits:\n",
    "        proportions, labels = to_proportions_and_labels(df_, split[1])\n",
    "        create_stacked_bar_chart(\n",
    "            f\"{grouping} {split[0]}\",\n",
    "            \"Response Summary\",\n",
    "            labels,\n",
    "            proportions,\n",
    "            savefig=savefig,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254aa4a-ec77-4273-8a11-4985070b7aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_sequence(\"Total\", rolled_up_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ffa4c-3eaa-4e80-b51f-d13c38e8f629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newer_families_rolled_up_data = calculate_question_totals(df[pd.to_numeric(df[\"Years at GVCA\"]) <= 3])\n",
    "plot_sequence(\"Newer Families\", newer_families_rolled_up_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8a24c-b2ed-4ab2-a224-44f938278582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "older_families_rolled_up_data = calculate_question_totals(df[pd.to_numeric(df[\"Years at GVCA\"]) > 3])\n",
    "plot_sequence(\"Older Families\", older_families_rolled_up_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989fa75-40a9-44b1-8e1b-8cbcb407eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"(Generic) Please provide us with examples of how GVCA can better serve you and your family.\"][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f494d8-5d9a-419d-8567-25a3acdef53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4o-mini allows you to process the entire data set, but is a lower quality model\n",
    "4o can handle subsets of the whole data, but theoretically produces better results\n",
    "\n",
    "evaluating the outcome indicates a superior response from 4o-mini\n",
    "though using 4o to enhance the taxonomies given both the 4o (detailed) and the 4o-mini (global) produces a taxonomy that is far superior\n",
    "\"\"\"\n",
    "\n",
    "class SurveyTaxonomyTag(BaseModel):\n",
    "    tag: str\n",
    "    explanation: str\n",
    "\n",
    "class SurveyTaxonomy(BaseModel):\n",
    "    tags: list[SurveyTaxonomyTag]\n",
    "\n",
    "taxonomy_prompt = f\"\"\"\n",
    "You are processing parent survey data from a school accountability committee. The parents were asked to provide feedback about which things have been working well and which things could be improved.\n",
    "\n",
    "Before diving into the data set you want to generate a set of tags that could be used to help contextualize and filter this free response data. It is acceptable if multiple tags could be applied to the same input. \n",
    "But you should attempt to broadly cover the survey results with this tag taxonomy.\n",
    "\n",
    "Each tag should be relevant to the content of the record and should consist of no more than 4 words. \n",
    "\n",
    "In addition to each tag, please provide a brief explanation of the tag (no more than 30 words). Generate no more than 30 tags in total.\n",
    "\n",
    "Here are the records:\n",
    "{bulleted_free_responses}\n",
    "\n",
    "Please generate the tags and explanations.\n",
    "\"\"\"\n",
    "\n",
    "text = df[\"Total Free Response\"].dropna().tolist()\n",
    "bulleted_free_responses = \"\\n\".join([\"- \"+re.sub(r'\\s+', ' ', t.replace(\"\\n\", \" \")).strip() for t in text[:50]])\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": taxonomy_prompt}\n",
    "    ],\n",
    "    response_format=SurveyTaxonomy,\n",
    ")\n",
    "\n",
    "for tag in completion.choices[0].message.parsed.tags:\n",
    "    print(f\"{tag.tag}: {tag.explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b68a4-5b94-4827-a45b-1905dc24d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = f\"\"\"\n",
    "You are processing parent survey data from a school accountability committee. The parents were asked to provide feedback about which things have been working well and which things could be improved.\n",
    "\n",
    "You have a taxonomy of classifications you want to label free response data with which is:\n",
    "{completion.choices[0].message.content}\n",
    "\n",
    "You want to evaluate the following and identify which categories should be applied to this free response input\n",
    "```input\n",
    "{df[\"(Generic) Please provide us with examples of how GVCA can better serve you and your family.\"][12]}\n",
    "```\n",
    "\n",
    "it is important to only provide the classifications that actually match to this free response and to not deviate from the provided taxonomy.\n",
    "please produce as a simple list\n",
    "\"\"\"\n",
    "prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81908ad1-3da3-4065-9d28-909caa07617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion2 = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt2}\n",
    "  ],\n",
    "    n=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c00ee8-4ae2-486e-92f4-0f3fbf92fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b56446-53f8-4aec-b900-9e44aaee0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(completion2.choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d029cac-6165-4f87-ae46-502f5078eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(completion2.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506087a-b917-4cb5-9370-516c7ea73138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"(Grammar) What makes GVCA a good choice for you and your family?\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
